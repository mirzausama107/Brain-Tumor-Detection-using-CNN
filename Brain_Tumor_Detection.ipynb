{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def crop_brain_contour(image, plot=False):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            \n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        \n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "\n",
    "        plt.title('Cropped Image')\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dir_list, image_size):\n",
    "    # load all images in a directory\n",
    "    X = []\n",
    "    y = []\n",
    "    image_width, image_height = image_size\n",
    "    \n",
    "    for directory in dir_list:\n",
    "        for filename in listdir(directory):\n",
    "            # load the image\n",
    "            image = cv2.imread(directory + '\\\\' + filename)\n",
    "            # crop the brain and ignore the unnecessary rest part of the image\n",
    "            image = crop_brain_contour(image, plot=False)\n",
    "            # resize image\n",
    "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "            # normalize values\n",
    "            image = image / 255.\n",
    "            # convert image to numpy array and append it to X\n",
    "            X.append(image)\n",
    "            # append a value of 1 to the target array if the image\n",
    "            # is in the folder named 'yes', otherwise append 0.\n",
    "            if directory[-3:] == 'yes':\n",
    "                y.append([1])\n",
    "            else:\n",
    "                y.append([0])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X, y = shuffle(X, y)\n",
    "    \n",
    "    print(f'Number of examples is: {len(X)}')\n",
    "    print(f'X shape is: {X.shape}')\n",
    "    print(f'y shape is: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples is: 2064\n",
      "X shape is: (2064, 240, 240, 3)\n",
      "y shape is: (2064, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "augmented_path =r'C:\\Users\\Muhammad Usama Abid\\Desktop\\uni\\augmented_data'\n",
    "\n",
    "# augmented data (yes and no) contains both the original and the new generated examples\n",
    "augmented_yes = os.path.join(augmented_path , 'yes')\n",
    "augmented_no = os.path.join(augmented_path , 'no')\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "\n",
    "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3) \n",
    "# X_val, y_val = 310, X_train, y_train = 1445 , X_test, y_test = 310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "  \n",
    "    # Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape) # shape=(?, 240, 240, 3)\n",
    "    \n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((2, 2))(X_input) # shape=(?, 244, 244, 3)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X) # shape=(?, 238, 238, 32)\n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool0')(X) # shape=(?, 59, 59, 32) \n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((4, 4), name='max_pool1')(X) # shape=(?, 14, 14, 32)\n",
    "    \n",
    "    # FLATTEN X \n",
    "    X = Flatten()(X) # shape=(?, 6272)\n",
    "    # FULLYCONNECTED\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X) # shape=(?, 1)\n",
    "    \n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = build_model(IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BrainDetectionModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 238, 238, 32)      4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 238, 238, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 238, 238, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 11,137\n",
      "Trainable params: 11,073\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m}:{round(s,1)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_f1_score(y_true, prob):\n",
    "    # convert the vector of probabilities to a target vector\n",
    "    y_pred = np.where(prob > 0.5, 1, 0)\n",
    "    \n",
    "    score = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(f\"Elapsed time: {hms_string(execution_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    \n",
    "    train_loss = history['loss']\n",
    "    val_loss = history['val_loss']\n",
    "    train_acc = history['accuracy']\n",
    "    val_acc = history['val_accuracy']\n",
    "    \n",
    "    # Loss\n",
    "    plt.figure()\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.figure()\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "history = model.history.history\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for key in history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 509ms/step - loss: 0.2509 - accuracy: 0.5226\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print (f\"Test Loss = {loss}\")\n",
    "print (f\"Test Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('brain-tumor-detection-CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BrainDetectionModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 240, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 244, 244, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 238, 238, 32)      4736      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 238, 238, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 238, 238, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pool0 (MaxPooling2D)     (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 11,137\n",
      "Trainable params: 11,073\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "new_model = load_model('brain-tumor-detection-CNN.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49410746]\n",
      "[0.9980666]\n",
      "[0.01362911]\n",
      "[0.18657252]\n",
      "[0.00275993]\n",
      "[0.9832089]\n",
      "[0.9897305]\n",
      "[0.9988812]\n",
      "[0.999759]\n",
      "[0.00023142]\n",
      "[3.2726828e-05]\n",
      "[0.99550986]\n",
      "[5.3533437e-05]\n",
      "[0.83686924]\n",
      "[0.05899534]\n",
      "[0.9970455]\n",
      "[0.9369131]\n",
      "[0.00487792]\n",
      "[0.9923124]\n",
      "[0.00202364]\n",
      "[0.0129441]\n",
      "[0.99997854]\n",
      "[0.9913244]\n",
      "[0.00043449]\n",
      "[0.81557]\n",
      "[0.00052491]\n",
      "[0.8574614]\n",
      "[0.00121778]\n",
      "[0.23388007]\n",
      "[0.11970419]\n",
      "[0.9957808]\n",
      "[0.5771359]\n",
      "[0.99938667]\n",
      "[0.43254554]\n",
      "[0.37187314]\n",
      "[0.07996193]\n",
      "[0.00269815]\n",
      "[0.00239012]\n",
      "[0.97233796]\n",
      "[0.97930884]\n",
      "[0.2905047]\n",
      "[0.00635245]\n",
      "[0.4772828]\n",
      "[0.00965342]\n",
      "[0.9997168]\n",
      "[0.36777943]\n",
      "[0.991458]\n",
      "[0.00010639]\n",
      "[0.02370632]\n",
      "[0.9999007]\n",
      "[0.78968513]\n",
      "[0.06134874]\n",
      "[0.00500569]\n",
      "[0.31351072]\n",
      "[0.04144242]\n",
      "[0.01903579]\n",
      "[0.9275755]\n",
      "[0.01870328]\n",
      "[0.11820567]\n",
      "[0.2891546]\n",
      "[0.95400286]\n",
      "[0.03833172]\n",
      "[0.01548702]\n",
      "[0.9992626]\n",
      "[0.02451098]\n",
      "[0.00338313]\n",
      "[0.14234358]\n",
      "[0.8273866]\n",
      "[0.99216354]\n",
      "[0.5588769]\n",
      "[0.37242895]\n",
      "[0.00221393]\n",
      "[0.11534318]\n",
      "[0.0410493]\n",
      "[0.935501]\n",
      "[0.97772384]\n",
      "[0.01519361]\n",
      "[0.9806727]\n",
      "[0.04397351]\n",
      "[0.9698874]\n",
      "[0.7334388]\n",
      "[0.7049333]\n",
      "[0.00118306]\n",
      "[0.00108185]\n",
      "[0.98010254]\n",
      "[0.05220294]\n",
      "[0.9859968]\n",
      "[0.93003136]\n",
      "[0.00727007]\n",
      "[0.88871384]\n",
      "[0.7269497]\n",
      "[0.01063359]\n",
      "[0.99451447]\n",
      "[0.61674625]\n",
      "[0.99993825]\n",
      "[0.9988351]\n",
      "[0.95622957]\n",
      "[0.07796004]\n",
      "[0.9745373]\n",
      "[0.00504577]\n",
      "[0.956543]\n",
      "[0.9999826]\n",
      "[0.00043443]\n",
      "[0.07563105]\n",
      "[0.00041521]\n",
      "[0.20336267]\n",
      "[0.8846885]\n",
      "[0.9997816]\n",
      "[0.99951065]\n",
      "[0.9974251]\n",
      "[0.8997829]\n",
      "[0.8730788]\n",
      "[3.3421627e-06]\n",
      "[0.937571]\n",
      "[0.02094439]\n",
      "[0.7988572]\n",
      "[0.03902745]\n",
      "[0.00031373]\n",
      "[0.99962854]\n",
      "[0.82087946]\n",
      "[0.132056]\n",
      "[0.80428565]\n",
      "[0.999989]\n",
      "[0.99573106]\n",
      "[0.91582906]\n",
      "[0.96863675]\n",
      "[0.9882164]\n",
      "[3.5591238e-05]\n",
      "[0.9659221]\n",
      "[0.5155005]\n",
      "[0.11057255]\n",
      "[0.0048241]\n",
      "[0.00312606]\n",
      "[0.174573]\n",
      "[0.99966717]\n",
      "[0.00993499]\n",
      "[0.999842]\n",
      "[0.08228183]\n",
      "[6.815291e-05]\n",
      "[0.5187132]\n",
      "[0.0009771]\n",
      "[0.16578782]\n",
      "[0.9960654]\n",
      "[0.9406169]\n",
      "[0.00294086]\n",
      "[0.12119332]\n",
      "[0.00852603]\n",
      "[0.01747897]\n",
      "[0.01355711]\n",
      "[0.00971934]\n",
      "[0.00326025]\n",
      "[0.22008362]\n",
      "[0.06633058]\n",
      "[0.00011865]\n",
      "[0.0050047]\n",
      "[0.99880993]\n",
      "[0.9939586]\n",
      "[0.9833616]\n",
      "[0.00114989]\n",
      "[0.98448676]\n",
      "[0.00063533]\n",
      "[0.46585158]\n",
      "[0.01099417]\n",
      "[0.9936882]\n",
      "[0.00227302]\n",
      "[0.11244711]\n",
      "[0.98957366]\n",
      "[0.929139]\n",
      "[0.7336469]\n",
      "[0.95573366]\n",
      "[0.24854335]\n",
      "[0.08851075]\n",
      "[0.02607054]\n",
      "[0.9998368]\n",
      "[0.98629236]\n",
      "[0.9945593]\n",
      "[0.9988395]\n",
      "[0.967973]\n",
      "[0.6123995]\n",
      "[0.9979577]\n",
      "[0.00023267]\n",
      "[0.96749306]\n",
      "[0.00042772]\n",
      "[0.98716587]\n",
      "[0.995988]\n",
      "[0.5073594]\n",
      "[0.03086719]\n",
      "[0.01525864]\n",
      "[0.99610573]\n",
      "[0.99991506]\n",
      "[0.46670234]\n",
      "[0.9716071]\n",
      "[0.33713648]\n",
      "[0.99983084]\n",
      "[0.9942581]\n",
      "[0.99970937]\n",
      "[0.64936215]\n",
      "[0.02583414]\n",
      "[0.11340824]\n",
      "[0.08737779]\n",
      "[0.9999269]\n",
      "[0.9815067]\n",
      "[0.04175985]\n",
      "[0.02433959]\n",
      "[0.91190886]\n",
      "[0.00028828]\n",
      "[0.99807745]\n",
      "[0.99963]\n",
      "[0.9262152]\n",
      "[0.966619]\n",
      "[0.5726321]\n",
      "[0.03053942]\n",
      "[0.9012065]\n",
      "[0.00016624]\n",
      "[0.6814548]\n",
      "[0.57367104]\n",
      "[0.03675127]\n",
      "[0.05519533]\n",
      "[0.9978584]\n",
      "[0.9998206]\n",
      "[0.20421645]\n",
      "[0.6065184]\n",
      "[0.09088671]\n",
      "[0.00267559]\n",
      "[0.99849886]\n",
      "[0.94651186]\n",
      "[0.49452376]\n",
      "[0.9971218]\n",
      "[7.5616845e-06]\n",
      "[0.01540107]\n",
      "[0.86058116]\n",
      "[0.97911775]\n",
      "[0.02058148]\n",
      "[0.05539456]\n",
      "[0.8833717]\n",
      "[0.024297]\n",
      "[0.9365865]\n",
      "[0.00144684]\n",
      "[0.9998946]\n",
      "[0.8686222]\n",
      "[0.8802348]\n",
      "[0.50237036]\n",
      "[0.08863291]\n",
      "[0.0508036]\n",
      "[0.9998723]\n",
      "[0.00251144]\n",
      "[0.9436854]\n",
      "[0.9546986]\n",
      "[0.9981133]\n",
      "[0.81058776]\n",
      "[0.00806749]\n",
      "[0.99609685]\n",
      "[0.23863205]\n",
      "[0.83743113]\n",
      "[0.8990631]\n",
      "[0.92218196]\n",
      "[0.00228548]\n",
      "[0.07543489]\n",
      "[0.00019604]\n",
      "[0.0144684]\n",
      "[0.07003668]\n",
      "[0.9781857]\n",
      "[0.2506003]\n",
      "[0.00104594]\n",
      "[0.99958503]\n",
      "[0.9999257]\n",
      "[0.42806232]\n",
      "[0.1645647]\n",
      "[0.9966725]\n",
      "[0.12332073]\n",
      "[0.08525187]\n",
      "[0.9998695]\n",
      "[0.98863184]\n",
      "[0.0425939]\n",
      "[0.00756755]\n",
      "[0.02041492]\n",
      "[0.68990827]\n",
      "[0.9890207]\n",
      "[0.06454906]\n",
      "[0.02382469]\n",
      "[0.04965481]\n",
      "[0.3066183]\n",
      "[0.99996805]\n",
      "[0.05865797]\n",
      "[0.09931171]\n",
      "[0.02452826]\n",
      "[0.99996835]\n",
      "[0.99800634]\n",
      "[0.9998019]\n",
      "[0.9875393]\n",
      "[0.03160983]\n",
      "[0.9154483]\n",
      "[7.700372e-05]\n",
      "[0.07722324]\n",
      "[0.9933696]\n",
      "[0.0051553]\n",
      "[0.00446588]\n",
      "[0.7979181]\n",
      "[0.00083444]\n",
      "[0.9999934]\n",
      "[0.9982574]\n",
      "[0.08601409]\n",
      "[0.99991643]\n",
      "[0.00307682]\n",
      "[0.04221637]\n",
      "[0.00282309]\n",
      "[0.9898837]\n",
      "[3.7011363e-05]\n",
      "[0.9998549]\n",
      "[0.5212568]\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict(X_test,batch_size=32, verbose = 0)\n",
    "#pred\n",
    "#np.argmax(pred)\n",
    "for i in pred:\n",
    "    print(i)\n",
    "    #n= int(i)\n",
    "    #print(np.argmax(pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"aug_Y65_0_7028.jpg\")\n",
    "#image.shape #(630,630,3)\n",
    "image_size = (240,240)\n",
    "image_width, image_height = image_size\n",
    "image = crop_brain_contour(image, plot=False)\n",
    "image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
    "image = image / 255.\n",
    "image = np.array(image).reshape(1,240,240,3)\n",
    "prediction = new_model.predict(image ,batch_size=32, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9853593]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "#catig = [\"yes\", \"no\"]\n",
    "#print(catig[np.argmax(predictions[0])])\n",
    "#print(np.argmax(prediction[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['yes', 'no']\n",
    "#predictions = model.predict([test_images])[0]\n",
    "predicted_label = class_names[np.argmax(prediction)]\n",
    "# Compare the predictions\n",
    "\n",
    "print(\"Predictions : \",predicted_label)\n",
    "#print(\"Actual : \", class_names[y_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "catig = [\"yes\", \"no\"]\n",
    "#rounded_predictions = new_model(X_test ,batch_size= 32, verbose = 0)\n",
    "predictions = model.predict(X ,batch_size= 10, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(['yes', 'no'])\n",
    "y_pred = np.array([1,0])\n",
    "compute_f1_score(y_val, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
